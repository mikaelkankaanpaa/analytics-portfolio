{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import sys\n",
    "\n",
    "\n",
    "def load_mnist_data(name):\n",
    "    if name == 'fashion':\n",
    "        print(\"Using the MNIST Fashion dataset\")\n",
    "        return fashion_mnist.load_data()\n",
    "    elif name == 'original':\n",
    "        print(\"Using the original MNIST dataset\")\n",
    "        return mnist.load_data()\n",
    "    else:\n",
    "        sys.exit(\"Invalid dataset name. Use 'mnist' or 'fashion'.\")\n",
    "\n",
    "\n",
    "def get_mean_and_cov(x_train, y_train, num_of_classes=10):\n",
    "    means = []\n",
    "    covariances = []\n",
    "    for c in range(num_of_classes):\n",
    "        samples = x_train[y_train == c]\n",
    "\n",
    "        # Mean vector for each class (across axis 0, ie. rows of the data matrix) \n",
    "        means.append(np.mean(samples, axis=0))\n",
    "\n",
    "        # Covariance matrix for each class\n",
    "        cov_matrix = np.cov(samples, rowvar=False)\n",
    "        # print(f\"For class no. {c}, the cov_matrix rank value is {np.linalg.matrix_rank(cov_matrix)}\")\n",
    "        covariances.append(cov_matrix)\n",
    "\n",
    "    return np.array(means), np.array(covariances)\n",
    "\n",
    "\n",
    "def classify(x_test, means, covariances):\n",
    "    num_of_classes = means.shape[0]\n",
    "    log_likelihoods = np.zeros((x_test.shape[0], num_of_classes))\n",
    "    \n",
    "    for c in range(num_of_classes):\n",
    "        # Multivariate normal distribution to calculate log likelihoods\n",
    "        mvn = multivariate_normal(mean=means[c], cov=covariances[c])\n",
    "        log_likelihoods[:, c] = mvn.logpdf(x_test)\n",
    "    \n",
    "    # Classify each sample by the class with the highest log likelihood\n",
    "    return np.argmax(log_likelihoods, axis=1)\n",
    "\n",
    "\n",
    "def class_acc(pred,gt):\n",
    "    res = gt-pred\n",
    "    acc = sum(x == 0 for x in res) / gt.shape[0]\n",
    "    return acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load the correct MNIST dataset & convert the image samples from 28x28 to 1x784\n",
    "    (x_train, y_train), (x_test, y_test) = load_mnist_data(sys.argv[-1])\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1) # 60000x784 training data matrix\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1) # 10000x784 test data matrix\n",
    "\n",
    "    # Add zero-mean Gaussian noise to the training data\n",
    "    noise_std = 35.0 # <-------------------------------------------------------- CHANGE FOR TESTING\n",
    "    print(f\"Classifying with noise_std of {noise_std}\")\n",
    "    x_train_noisy = x_train + np.random.normal(loc=0.0, scale=noise_std, size=x_train.shape)\n",
    "\n",
    "    # Compute mean and covariance for each class using noisy data\n",
    "    means, covariances = get_mean_and_cov(x_train_noisy, y_train)\n",
    "\n",
    "    # Classify test samples\n",
    "    y_pred = classify(x_test, means, covariances)\n",
    "\n",
    "    # Calculate & print the classification accuracy\n",
    "    acc = class_acc(y_pred, y_test)\n",
    "    print(f\"Classification accuracy is {acc * 100:.2f} %\")\n",
    "    print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
